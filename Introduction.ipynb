{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Security R&D AI Hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome!\n",
    "\n",
    "This is an introductory Notebook for using GPT via Azure OpenAI\n",
    "\n",
    "The purpose of this notebook is to provide first easy step for using GenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI API key\n",
    "* First, you will need to get an API [Key](https://wiki.checkpoint.com/confluence/pages/viewpage.action?pageId=554281566#CloudSecurityR&DAIHackathon-AI_ENVIRONMENT).\n",
    "* Watch out - these keys have limits, don't massivly use them - or you'll hit your limits!\n",
    "\n",
    "#### Sensitive information in your code\n",
    "* Hard-coding API keys is tempting, but creates problems when sharing the project.\n",
    "* In this Notebook we will hard-code these values anyway.\n",
    "* For a better, more secure approach, see the equivallent `app` directory\n",
    "\n",
    "#### openai package\n",
    "* We will use `openai` Python package for communicating with GPT\n",
    "* If you don't have it installed, uncomment the cell below\n",
    "* If you're missing the package, you'll get a `ModuleNotFoundError: No module named 'openai'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\"  # See details above. Replace <openai_API_key> with your API key.\n",
    "ENDPOINT = \"https://staging-dev-openai.azure-api.net/openai-gw-proxy-dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The product of 10 multiplied by 10 is 100.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "# Use AzureOpenAI to create a client that allows sending API requests to GPT\n",
    "client = AzureOpenAI(azure_endpoint=ENDPOINT, api_key=API_KEY, api_version=\"2023-07-01-preview\")\n",
    "\n",
    "# Define a prompt you'll sent to GPT\n",
    "query = 'What is 10 times 10?'\n",
    "\n",
    "# Send the query to OpenAI\n",
    "res = client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\", messages=[{\"role\": \"user\", \"content\": query}]\n",
    ")\n",
    "\n",
    "# Parse OpenAI's response\n",
    "parsed_response = res.choices[0].message.content\n",
    "\n",
    "# Let's see what we've got\n",
    "print(parsed_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A function for querying + parsign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The biggest city in the world by population is Tokyo, Japan. As of 2021, Tokyo has a population of approximately 37.9 million people.\n"
     ]
    }
   ],
   "source": [
    "def query_gpt_and_parse(prompt: str, model: str=\"gpt-35-turbo\") -> str:\n",
    "    \"\"\"\n",
    "    A function that uses OpenAI's sdk to query GPT.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The input string to be sent to the GPT model.\n",
    "        model (str): The specific model to use for the query (default is \"gpt-35-turbo\").\n",
    "\n",
    "    Returns:\n",
    "        str: The text response generated by the GPT model.\n",
    "    \"\"\"\n",
    "    res = client.chat.completions.create(\n",
    "        model=model, messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    parsed_response = res.choices[0].message.content\n",
    "    return parsed_response\n",
    "\n",
    "\n",
    "prompt = \"What is the biggest city in the world by population?\"\n",
    "parsed_res = query_gpt_and_parse(prompt)\n",
    "print(parsed_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "* [Hackathon main wiki page](https://wiki.checkpoint.com/confluence/pages/viewpage.action?pageId=554281566)\n",
    "* [API keys for Hackathon](https://wiki.checkpoint.com/confluence/pages/viewpage.action?pageId=554281566#CloudSecurityR&DAIHackathon-AI_ENVIRONMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
