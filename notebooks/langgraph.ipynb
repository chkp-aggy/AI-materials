{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "wwmyaRZcnVXe"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import io\n",
        "import os\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langgraph.pregel import GraphRecursionError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w7_S6idrRnm"
      },
      "source": [
        "## Input parsing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRgH2XHQlluT",
        "outputId": "67433d0b-ead2-4202-e30b-7d2e9b3a3cad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['class.csv', 'query_input.txt', 'temperature.ipynb', 'README.md', 'class_reflect.txt', 'class_errors.txt', 'others', 'class.py', 'langgraph.ipynb', 'class.txt', 'class_query.txt', 'langchain.ipynb']\n"
          ]
        }
      ],
      "source": [
        "print(os.listdir())  # Your query_input.txt and datafile should be listed here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "FlCfLekVnYvT"
      },
      "outputs": [],
      "source": [
        "# Read what which files and operations we are expected to perform (query input)\n",
        "def read_query_input(query_input_file):\n",
        "    try:\n",
        "        with open(query_input_file) as f:\n",
        "            query_input_content = [line.strip() for line in f.readlines()]\n",
        "        partially_parsed = [line.split(':') for line in query_input_content[:-1]]\n",
        "        info = {line[0]: line[1] for line in partially_parsed}\n",
        "        info['columns'] = info['columns'].split(',')\n",
        "        return info\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file {query_input_file} was not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading {query_input_file}: {str(e)}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "collapsed": true,
        "id": "JATkeSEvj-qD"
      },
      "outputs": [],
      "source": [
        "def read_data_file(data_file):\n",
        "    try:\n",
        "        assert data_file.endswith('.csv'), \"The data file must be a CSV file.\"\n",
        "        data_file_content = pd.read_csv(data_file)\n",
        "        return data_file_content\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file {data_file} was not found.\")\n",
        "        return None\n",
        "    except AssertionError as ae:\n",
        "        print(f\"Error: {str(ae)}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading {data_file}: {str(e)}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "a3WmHkD0pCEa"
      },
      "outputs": [],
      "source": [
        "def read_query_file(query_file):\n",
        "    try:\n",
        "        query_file_name = query_file + '_query.txt'\n",
        "        with open(query_file_name) as f:\n",
        "            return f.read()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file {query_file_name} was not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading {query_file_name}: {str(e)}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "FT5SN-shOIPy"
      },
      "outputs": [],
      "source": [
        "def read_input(state):\n",
        "  print(\"Executing Agent Initialize\")  # This method is called by the first node\n",
        "  query_input = read_query_input('query_input.txt')\n",
        "\n",
        "  data_file = query_input.get('data_file')\n",
        "  state['data_file'] = data_file\n",
        "\n",
        "  data = read_data_file(data_file)\n",
        "  state['data'] = data  # Adding the data to the state\n",
        "\n",
        "  query_name = query_input.get('query_name')\n",
        "  state['query_name'] = query_name\n",
        "\n",
        "  query = read_query_file(query_name)\n",
        "  state['query'] = query  # Adding the query to the state\n",
        "\n",
        "  columns = query_input.get('columns')\n",
        "  state['columns'] = columns\n",
        "\n",
        "  return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiPdJ-GYxUE6"
      },
      "source": [
        "## Setting up LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"\"\n",
        "\n",
        "AZURE_OPENAI_API_KEY = os.getenv('AZURE_OPENAI_API_KEY')\n",
        "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "\n",
        "\n",
        "model = AzureChatOpenAI(\n",
        "    azure_deployment=\"gpt-4\",\n",
        "    api_version=\"2023-06-01-preview\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': None}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-505332b9-e80b-4fae-9f18-87784ec56d77-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17})"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.invoke('hello')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihh6H0PE6WV4"
      },
      "source": [
        "## LangGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "3IZdZ9DNMV07"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "# state that is passed around graph\n",
        "class State(TypedDict):\n",
        "  query_name: str\n",
        "  query: str\n",
        "  data_file: str\n",
        "  data: str\n",
        "  columns: List[str]\n",
        "  query_code: str\n",
        "  execution_number: int\n",
        "  execution_result: str\n",
        "  error_check: bool\n",
        "  error_message: str\n",
        "  reflection: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "dcutezTAjgNu"
      },
      "outputs": [],
      "source": [
        "def clean_code(code):\n",
        "    '''\n",
        "    Strips away the tickmark (`) surrounding the code.\n",
        "    '''\n",
        "    if '`' in code:\n",
        "      start = code.find(\"`\")\n",
        "      code = code[start+9:]  # Removing code opening: ```python\n",
        "      end = code.find(\"`\")  # Removing closing ```\n",
        "      code = code[:end]\n",
        "    return code.strip()\n",
        "\n",
        "\n",
        "def generate_program(state):\n",
        "  print(\"Executing Agent GenQueryProgram\")  # Invoked by the 2nd node\n",
        "\n",
        "  prompt_format = (\n",
        "      \"I have data in `csv` format in {} containing the following columns: {}\\n\"\n",
        "      \"I want you to write a valid Python function the performs the following: {}\\n\\n\"\n",
        "      \"Note: I will insert your code into a Python interpreter, so make sure your\"\n",
        "      \" response is valid Python code, without any other output.\"\n",
        "      \" Make sure you do not include any introduction, explanation, or summarization of your answer.\"\n",
        "      \" The last line of your code should be printing the result JSON\"\n",
        "  )\n",
        "\n",
        "  # call llm to get response\n",
        "  code = model.invoke(prompt_format.format(state['data_file'], state['columns'], state['query'])).content\n",
        "  cleaned_code = clean_code(code)\n",
        "\n",
        "  state['query_code'] = cleaned_code\n",
        "  return state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "l-73awNvADBs"
      },
      "outputs": [],
      "source": [
        "# Executes the program, adds the output/error to the state\n",
        "def execute_program(state):\n",
        "  state['execution_number'] += 1\n",
        "  print(f\"Executing Agent ExecuteProgram (Execution number {state['execution_number']})\")\n",
        "\n",
        "  code = state['query_code']\n",
        "\n",
        "  # Redirect stdout to capture the output\n",
        "  old_stdout = sys.stdout\n",
        "  redirected_output = sys.stdout = io.StringIO()\n",
        "\n",
        "  try:\n",
        "    exec(code)\n",
        "    output = redirected_output.getvalue()\n",
        "  except Exception as e:\n",
        "    output = \"[ERROR] Execution failed: \" + str(e)\n",
        "  finally:\n",
        "    sys.stdout = old_stdout\n",
        "\n",
        "  state['execution_result'] = output\n",
        "  return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "MdibTyL8HqDp"
      },
      "outputs": [],
      "source": [
        "def check_errors(state):\n",
        "  print(\"Executing Agent Chk4rErr\")\n",
        "\n",
        "  def is_json(myjson):\n",
        "    try:\n",
        "      json.loads(myjson)\n",
        "    except ValueError as e:\n",
        "      return False\n",
        "    return True\n",
        "\n",
        "  output = state['execution_result']\n",
        "  errors_found = False\n",
        "\n",
        "  if output.startswith(\"[ERROR]\"):  # Encountered an exception\n",
        "    msg = state['execution_result']\n",
        "  elif not output:  # Empty response\n",
        "    msg = \"Empty response\"\n",
        "  elif not is_json(output):  # Invalid JSON\n",
        "    msg = \"Invalid JSON\"\n",
        "  else:\n",
        "    state['error_check'] = False\n",
        "    return state\n",
        "\n",
        "  state['error_check'] = True\n",
        "  state['error_message'] = msg\n",
        "  return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "LMRHRcAZKL9x"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "def reflect_on_error(state):\n",
        "  print(\"Executing Agent ReflectOnErr\")\n",
        "\n",
        "  code = state['query_code']\n",
        "  error = state['error_message']\n",
        "\n",
        "  system_prompt = (\n",
        "    \"You're a Python programming assitant.\"\n",
        "    \" You are presented with user code and a resulting error.\"\n",
        "    \" Your mission is to explain the problem,\"\n",
        "    \" and suggest ways to fix it.\"\n",
        "  )\n",
        "\n",
        "  user_prompt = (\n",
        "      \"I encountered a bug in my Python code.\"\n",
        "      \" Could you help me understand my mistake?\\n\"\n",
        "      \"The problem I encounter is:\\n{error}.\\n\"\n",
        "      \"Here is the code:\\n{code}\"\n",
        "      )\n",
        "\n",
        "  template = ChatPromptTemplate.from_messages([\n",
        "      (\"system\", (system_prompt)),\n",
        "      (\"human\", (user_prompt))\n",
        "  ])\n",
        "\n",
        "  prompt_value = template.invoke({\n",
        "      \"error\": error,\n",
        "      \"code\": code\n",
        "  })\n",
        "\n",
        "  reflection = model.invoke(prompt_value).content\n",
        "  state['reflection'] = reflection\n",
        "  return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "oYKeDE3_QMnD"
      },
      "outputs": [],
      "source": [
        "def should_retry(state):\n",
        "  print(\"Executing Conditional Edge (ReGenQueryPgm or Finalize)\")\n",
        "  if state['error_check']:\n",
        "    # print(f\"Found an error {state['error_message']}, retrying...\")\n",
        "    return 'ReflectOnErr'  # Error detected. Reflect, rewrite, retest.\n",
        "  # print(\"Solution seems fine, proceeding!\")\n",
        "  return \"Finalize\"  # Will move to the finalizing agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "UGLii_NjRDyh"
      },
      "outputs": [],
      "source": [
        "def regenerate_code(state):\n",
        "  print(\"Executing Agent ReGenQueryPgm\")\n",
        "\n",
        "  template = (\n",
        "      \"I'm trying to write a Python script that {query}.\"\n",
        "      \" My data is saved in a file called {query_name},\"\n",
        "      \" and contains the following columns: {columns}\\n\"\n",
        "      \"I got the following error when running my implementation:\\n{error}\\n\"\n",
        "      \"Here is my code: {code}\\n\"\n",
        "      \"Please help me modify my code so it runs properly.\"\n",
        "      \"Please respond with a fixed version of my code.\"\n",
        "      \" I will insert your response into a Python interpreter,\"\n",
        "      \" so make sure your response is valid Python code,\"\n",
        "      \" without any introduction or explanation,\"\n",
        "      \" or without any other output.\"\n",
        "      \" Specifically, do not start your reply with 'certainly', or 'sure,\"\n",
        "      \" simply respond with valid python code.\"\n",
        "  )\n",
        "\n",
        "  prompt = template.format(query_name=state['data_file'],\n",
        "                           columns=state['columns'],\n",
        "                           query=state['query'],\n",
        "                           error=state['error_message'],\n",
        "                           code=state['query_code'],\n",
        "                           # hint=state['reflection']\n",
        "                           )\n",
        "\n",
        "  code = model.invoke(prompt).content\n",
        "  cleaned_code = clean_code(code)\n",
        "\n",
        "  # print(f\"\\n\\n***{cleaned_code}***\\n\\n\")\n",
        "  state['query_code'] = cleaned_code\n",
        "  return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "JguNCkqMRw7F"
      },
      "outputs": [],
      "source": [
        "def finalize(state):\n",
        "  print(\"Executing Agent Finalize\")\n",
        "\n",
        "  query_name = state['query_name']\n",
        "  code = state['query_code']\n",
        "  output = state['execution_result']\n",
        "  errors = state['error_message'] if state['error_message'] else \"\"\n",
        "  reflection = state['reflection']\n",
        "\n",
        "  with open(f'{query_name}.py', 'w') as code_f:\n",
        "    code_f.write(code)\n",
        "\n",
        "  with open(f'{query_name}.txt', 'w') as output_f:\n",
        "    output_f.write(output)\n",
        "\n",
        "  with open(f'{query_name}_errors.txt', 'w') as errors_f:\n",
        "    errors_f.write(errors)\n",
        "\n",
        "  with open(f'{query_name}_reflect.txt', 'w') as reflection_f:\n",
        "    reflection_f.write(reflection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "collapsed": true,
        "id": "JS25qZTU9sFA"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END, StateGraph\n",
        "\n",
        "\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "# Part I: Deterministic flow. Will allows run.\n",
        "\n",
        "# Initial agent, reading input\n",
        "workflow.add_node(\"Initialize\", read_input)\n",
        "workflow.set_entry_point(\"Initialize\")\n",
        "\n",
        "# Agents that writes Python code for the query\n",
        "workflow.add_node(\"GenQueryProgram\", generate_program)\n",
        "workflow.add_edge(\"Initialize\", \"GenQueryProgram\")\n",
        "\n",
        "# Agent that runs the Python code generated in last step\n",
        "workflow.add_node(\"ExecuteProgram\", execute_program)\n",
        "workflow.add_edge(\"GenQueryProgram\", \"ExecuteProgram\")\n",
        "\n",
        "# Agent that checks for errors in the code execution\n",
        "workflow.add_node(\"Chk4rErr\", check_errors)\n",
        "workflow.add_edge(\"ExecuteProgram\", \"Chk4rErr\")\n",
        "\n",
        "\n",
        "# Part II: Conditional flow\n",
        "\n",
        "workflow.add_node(\"ReflectOnErr\", reflect_on_error)\n",
        "workflow.add_conditional_edges(\"Chk4rErr\", should_retry)  # Continue to ReflectOnErr or to Finalize, depending on errors\n",
        "\n",
        "\"\"\"\n",
        "NOTE:\n",
        "Instead of using the `regenrate_code` function, we are now using the\n",
        "`generate program` function itself again.\n",
        "Our attempts so far with prompt engineering the regenerate function\n",
        "did not succeed, and attempting to solve the query from scratch did.\n",
        "\"\"\"\n",
        "workflow.add_node(\"ReGenQueryPgm\", regenerate_code)\n",
        "workflow.add_edge(\"ReflectOnErr\", \"ReGenQueryPgm\")\n",
        "\n",
        "# Close a cycle in the graph:\n",
        "# execute -> check for errors -> reflect -> regenerate -> execute..\n",
        "# Continue cycling until solution seems fine\n",
        "workflow.add_edge(\"ReGenQueryPgm\", \"ExecuteProgram\")\n",
        "\n",
        "workflow.add_node(\"Finalize\", finalize)\n",
        "workflow.add_edge(\"Finalize\", END)\n",
        "\n",
        "runnable = workflow.compile()\n",
        "mystate = State(query=\"\", execution_number=0, error_message=\"\", reflection=\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQDUQsMejiam",
        "outputId": "2260d33f-cd7d-4215-b12a-14ffd0c98ce9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Agent Initialize\n",
            "Executing Agent GenQueryProgram\n",
            "Executing Agent ExecuteProgram (Execution number 1)\n",
            "Executing Agent Chk4rErr\n",
            "Executing Conditional Edge (ReGenQueryPgm or Finalize)\n",
            "Executing Agent ReflectOnErr\n",
            "Executing Agent ReGenQueryPgm\n",
            "Executing Agent ExecuteProgram (Execution number 2)\n",
            "Executing Agent Chk4rErr\n",
            "Executing Conditional Edge (ReGenQueryPgm or Finalize)\n",
            "Executing Agent Finalize\n"
          ]
        }
      ],
      "source": [
        "results = {}  # Initialize results to an empty dictionary\n",
        "\n",
        "try:\n",
        "    results = runnable.invoke(mystate)\n",
        "except GraphRecursionError:\n",
        "    print(\"Error: Recursion limit reached without resolving the issue. Please rephrase your query and try again.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {str(e)}\")\n",
        "\n",
        "# if results:\n",
        "#     print(*[f\"{k}: {v}\" for k, v in results.items()], sep='\\n' + \"*\" * 10 + '\\n')\n",
        "# else:\n",
        "#     print(\"No results to display due to an error during execution.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Py6lnD_VXN8a",
        "outputId": "0ddb6a93-d4b4-4bd6-9dad-81bb66c5931a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"First\": \"Shalom\", \"Last\": \"Levi\", \"Year\": 3, \"Average-Grade\": 92.4}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# print(*[f\"{k}: {v}\" for k, v in results.items()], sep='\\n' + \"*\" * 10 + '\\n')\n",
        "print(results['execution_result'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cju1u4_9rIcD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
